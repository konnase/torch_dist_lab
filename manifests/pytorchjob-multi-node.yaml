apiVersion: "kubeflow.org/v2alpha1"
kind: "PyTorchJob"
metadata:
  # name: "pytorch-cifar-ddp"
  generateName: "pytorch-cifar-ddp-"
spec:
  # priorityClassName: high
  # preemptible: true
  # topologyGPU: true
  # useSpot: true
  backoffLimit: 0
  architecture: DDP
  pytorchReplicaSpecs:
    Master:
      replicas: 1 # must be 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: pytorch
              image: registry.sensetime.com/cloudnative4ai/pytorch/cifar-ddp:cuda11.0
              imagePullPolicy: Always
              command: ["/bin/bash", "-c",]
              args: 
              - >
                python3 -m torch.distributed.launch 
                --nproc_per_node=$NPROC_PER_NODE 
                --nnodes=$NNODES 
                --node_rank=$NODE_RANK 
                --master_addr=$MASTER_ADDR 
                --master_port=$MASTER_PORT
                cifar.py --arch=resnet --epochs 300
              resources: 
                limits:
                  cpu: 9
                  memory: 20Gi
                  nvidia.com/gpu: 4
              workingDir: /torch-dist/cifar
              volumeMounts:
              - mountPath: /dev/shm
                name: cache-volume
          volumes:
          - name: cache-volume
            emptyDir:
              medium: Memory
              sizeLimit: 2Gi
    Worker:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: pytorch
              image: registry.sensetime.com/cloudnative4ai/pytorch/cifar-ddp:cuda11.0
              imagePullPolicy: Always
              command: ["/bin/bash", "-c",]
              args: 
              - >
                python3 -m torch.distributed.launch 
                --nproc_per_node=$NPROC_PER_NODE 
                --nnodes=$NNODES 
                --node_rank=$NODE_RANK 
                --master_addr=$MASTER_ADDR 
                --master_port=$MASTER_PORT
                cifar.py --arch=resnet --epochs 300
              resources: 
                limits:
                  cpu: 9
                  memory: 20Gi
                  nvidia.com/gpu: 4
              workingDir: /torch-dist/cifar
              volumeMounts:
              - mountPath: /dev/shm
                name: cache-volume
          volumes:
          - name: cache-volume
            emptyDir:
              medium: Memory
              sizeLimit: 2Gi